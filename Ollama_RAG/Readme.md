# Retrieval Augmented Generation (RAG) Web Query Tool: On-Device Streamlit App

This Python application implements Retrieval Augmented Generation (RAG) using Ollama, a locally installed tool. The app allows querying a set of webpages with a question using a retrieve and read approach powered by Ollama. The vectorstore enables relevant passages from the webpages to be retrieved based on the question.

## Features

- Takes in a list of URLs and a question string.
- Uses a WebBaseLoader to load the webpage content for each URL.
- Splits the loaded text into chunks using a CharacterTextSplitter.
- Converts the text chunks into embeddings using OllamaEmbeddings (The nomic-embed-text model is used). These embeddings are indexed in the Chroma vectorstore.
- Defines an "after RAG" prompt that provides the vectorstore context and asks the question.
- Passes this prompt to an Ollama model and returns the response via the retriever which will be invoked to find the most relevant text chunks from the vectorstore given the question.

## Streamlit App

- Takes URL and question input from the user.
- Calls process_input when the button is clicked.
- Shows the Ollama response for the given URLs and question.

## Main Tools/Libraries Used

- **Streamlit**: For building the web app UI and interactivity.
- **WebBaseLoader**: To load the contents of the webpages from the input URLs.
- **LangChain**: To construct the pipelines and prompt templates for the retrieve and read model.
- **Ollama â€“ Mistral**: Used Mistral as the large language model to actually read/comprehend the documents and answer the question.
- **OllamaEmbeddings (nomic-embed-text model)**: To generate embeddings of the text chunks for storage in Chroma.
- **Chroma DB**: The vectorstore used to index the webpage contents and retrieve relevant passages.
- **CharacterTextSplitter**: To split the webpage contents into suitable chunks for embedding.

## Usage

To run the application locally:

1. Install the required dependencies listed in `requirements.txt`.
2. Make sure Ollama and Chroma are properly set up and configured on your system.
3. Run `streamlit run rag_app.py` in your terminal.
4. Access the app in your browser at the provided address.

## Example

Here's a brief example of how to use the app:

1. Enter the URLs of the webpages you want to query.
2. Type in your question.
3. Click on the "Submit" button.
4. The app will display the response generated by Ollama based on the provided URLs and question.

## License

[MIT License](LICENSE)

